{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrROhwC5Hp9e"
      },
      "source": [
        "# Week 10\n",
        "# TensorFlow/Keras Sequential API and CNNs\n",
        "\n",
        "**Big thank you to Professor Liang Zhao much of the material in this workbook**\n",
        "\n",
        "Extra Material on RNNs not covered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMZhberOHpSb"
      },
      "source": [
        "## I. Tensorflow.keras and Sequential API\n",
        "\n",
        "In this notebook we use the Keras Sequential API. In class, we cover the Keras Fuctional API and we may leverage this in the material on Transformers. Note: the Functional API allows us to directly specifiy which output form previous layers to use as inputs instead of just sequentially adding layers (recall skip connections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy-e88qXlZC3",
        "outputId": "9d604589-50c1-4e2e-a492-c8c03bd14905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LElKsHuBlx9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "134ee470-5cd7-4e87-af40-fdde192917ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = K.models.Sequential([\n",
        "    K.layers.Flatten(input_shape=(28, 28)),\n",
        "    K.layers.Dense(128, input_shape=(784,), activation='relu'),\n",
        "    K.layers.Dense(10)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E2elKX0mJcK"
      },
      "outputs": [],
      "source": [
        "model = K.models.Sequential()\n",
        "model.add(K.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(K.layers.Dense(256, input_shape=(784,), activation='relu'))\n",
        "model.add(K.layers.Dense(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "0ND7b49ymVUx",
        "outputId": "689b1f24-d2c9-4fb6-f9ee-080eae570c19"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m200,960\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m203,530\u001b[0m (795.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,530</span> (795.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m203,530\u001b[0m (795.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,530</span> (795.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSEx-4HLmXL1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.000001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        "),\n",
        "              loss=K.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "          metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP2G2b-Imgs7",
        "outputId": "17d15c80-af74-4c0d-ca30-b466235f3d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Load FashionMNIST data\n",
        "fashion_mnist = K.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "print(train_images.shape, test_images.shape)\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW2pdLDRJ-SR"
      },
      "source": [
        "### If we use 90/10 spit with batch size 32, what is the batch size?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozt7Kgy7d6dt",
        "outputId": "79efd91c-c50a-41bb-f911-1bfb0f49a85e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1687.5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "60000 * 0.9 / 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPZV_YiQmy7X",
        "outputId": "8c816e0d-8760-4aa5-8d82-50cd0de65096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1654 - loss: 2.3413 - val_accuracy: 0.3737 - val_loss: 1.9401\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4182 - loss: 1.8671 - val_accuracy: 0.5817 - val_loss: 1.6285\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 1.5831 - val_accuracy: 0.6637 - val_loss: 1.4037\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6546 - loss: 1.3745 - val_accuracy: 0.6907 - val_loss: 1.2409\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6792 - loss: 1.2271 - val_accuracy: 0.7032 - val_loss: 1.1221\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6903 - loss: 1.1170 - val_accuracy: 0.7163 - val_loss: 1.0336\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 1.0342 - val_accuracy: 0.7225 - val_loss: 0.9662\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7129 - loss: 0.9738 - val_accuracy: 0.7340 - val_loss: 0.9141\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.9277 - val_accuracy: 0.7395 - val_loss: 0.8724\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.8799 - val_accuracy: 0.7473 - val_loss: 0.8382\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b7a71678670>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, batch_size=32, epochs=10, verbose=1,\n",
        "          validation_split=0.1,\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA4Cxet3m7kK",
        "outputId": "212e87fc-f2af-4403-d6e4-f7720d7e45be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7327 - loss: 0.8626\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ombEII-ipiDl",
        "outputId": "5775d8f8-350b-4f72-9003-38cc2f37500e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.868\n",
            "Test accuracy: 0.730\n"
          ]
        }
      ],
      "source": [
        "print(\"Test loss: {:.3f}\".format(scores[0]))\n",
        "print(\"Test accuracy: {:.3f}\".format(scores[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mla1aECZp71i",
        "outputId": "f350702a-0ffa-474b-a2c3-cd5503cce880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.8498 - val_accuracy: 0.7542 - val_loss: 0.8101\n",
            "Epoch 2/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.8199 - val_accuracy: 0.7588 - val_loss: 0.7860\n",
            "Epoch 3/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.8025 - val_accuracy: 0.7642 - val_loss: 0.7653\n",
            "Epoch 4/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7608 - loss: 0.7788 - val_accuracy: 0.7687 - val_loss: 0.7473\n",
            "Epoch 5/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7617 - loss: 0.7626 - val_accuracy: 0.7708 - val_loss: 0.7311\n",
            "Epoch 6/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7709 - loss: 0.7410 - val_accuracy: 0.7735 - val_loss: 0.7169\n",
            "Epoch 7/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7749 - loss: 0.7285 - val_accuracy: 0.7768 - val_loss: 0.7039\n",
            "Epoch 8/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7765 - loss: 0.7165 - val_accuracy: 0.7795 - val_loss: 0.6925\n",
            "Epoch 9/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.7087 - val_accuracy: 0.7830 - val_loss: 0.6821\n",
            "Epoch 10/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7819 - loss: 0.6934 - val_accuracy: 0.7867 - val_loss: 0.6721\n",
            "Epoch 11/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7875 - loss: 0.6803 - val_accuracy: 0.7890 - val_loss: 0.6633\n",
            "Epoch 12/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7857 - loss: 0.6817 - val_accuracy: 0.7902 - val_loss: 0.6546\n",
            "Epoch 13/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7919 - loss: 0.6613 - val_accuracy: 0.7918 - val_loss: 0.6471\n",
            "Epoch 14/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7936 - loss: 0.6541 - val_accuracy: 0.7940 - val_loss: 0.6398\n",
            "Epoch 15/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7970 - loss: 0.6489 - val_accuracy: 0.7953 - val_loss: 0.6333\n",
            "Epoch 16/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.6436 - val_accuracy: 0.7982 - val_loss: 0.6266\n",
            "Epoch 17/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.6319 - val_accuracy: 0.8012 - val_loss: 0.6202\n",
            "Epoch 18/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8015 - loss: 0.6291 - val_accuracy: 0.8017 - val_loss: 0.6143\n",
            "Epoch 19/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.6230 - val_accuracy: 0.8035 - val_loss: 0.6086\n",
            "Epoch 20/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8070 - loss: 0.6116 - val_accuracy: 0.8050 - val_loss: 0.6037\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=20, verbose=1,\n",
        "                    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "YeU1KfDTqHpK",
        "outputId": "3987b8f2-75cc-456b-f3bb-21b8f9057190"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pd.DataFrame(history.history).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooxNcxF6qXXr",
        "outputId": "ace73687-ba40-4f88-ed3c-fd28b92012ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5784 - accuracy: 0.8016\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8462\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5722 - accuracy: 0.8071\n",
            "375/375 [==============================] - 0s 958us/step - loss: 0.4571 - accuracy: 0.8370\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5812 - accuracy: 0.8015\n",
            "375/375 [==============================] - 0s 915us/step - loss: 0.4898 - accuracy: 0.8214\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5575 - accuracy: 0.8048\n",
            "375/375 [==============================] - 0s 962us/step - loss: 0.4352 - accuracy: 0.8504\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5839 - accuracy: 0.7993\n",
            "375/375 [==============================] - 0s 967us/step - loss: 0.4606 - accuracy: 0.8348\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5456 - accuracy: 0.8136\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.8479\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5384 - accuracy: 0.8132\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8474\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5454 - accuracy: 0.8089\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8572\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5407 - accuracy: 0.8105\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8474\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5407 - accuracy: 0.8148\n",
            "375/375 [==============================] - 0s 990us/step - loss: 0.4433 - accuracy: 0.8439\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5034 - accuracy: 0.8213\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3921 - accuracy: 0.8585\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5028 - accuracy: 0.8222\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.4239 - accuracy: 0.8468\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5072 - accuracy: 0.8231\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.8562\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5028 - accuracy: 0.8210\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.4206 - accuracy: 0.8546\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5007 - accuracy: 0.8244\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.4846 - accuracy: 0.8301\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5625 - accuracy: 0.8080\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4302 - accuracy: 0.8504\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3915 - accuracy: 0.8627\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3703 - accuracy: 0.8687\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3542 - accuracy: 0.8728\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8609\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5563 - accuracy: 0.8099\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4133 - accuracy: 0.8554\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3792 - accuracy: 0.8647\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3554 - accuracy: 0.8739\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3399 - accuracy: 0.8797\n",
            "375/375 [==============================] - 0s 914us/step - loss: 0.3734 - accuracy: 0.8654\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5827 - accuracy: 0.8009\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4220 - accuracy: 0.8507\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3855 - accuracy: 0.8612\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3646 - accuracy: 0.8683\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3471 - accuracy: 0.8739\n",
            "375/375 [==============================] - 0s 850us/step - loss: 0.3795 - accuracy: 0.8606\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5759 - accuracy: 0.8012\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4234 - accuracy: 0.8502\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3876 - accuracy: 0.8616\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3622 - accuracy: 0.8700\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3456 - accuracy: 0.8747\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8669\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5684 - accuracy: 0.8036\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4221 - accuracy: 0.8523\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3853 - accuracy: 0.8622\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3607 - accuracy: 0.8722\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3456 - accuracy: 0.8780\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8682\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5473 - accuracy: 0.8089\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4142 - accuracy: 0.8522\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3684 - accuracy: 0.8667\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3436 - accuracy: 0.8755\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3241 - accuracy: 0.8824\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8764\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5379 - accuracy: 0.8157\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4003 - accuracy: 0.8565\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3615 - accuracy: 0.8696\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3372 - accuracy: 0.8776\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3220 - accuracy: 0.8839\n",
            "375/375 [==============================] - 0s 988us/step - loss: 0.3585 - accuracy: 0.8695\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5443 - accuracy: 0.8090\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4157 - accuracy: 0.8520\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3757 - accuracy: 0.8650\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3514 - accuracy: 0.8728\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3294 - accuracy: 0.8802\n",
            "375/375 [==============================] - 0s 981us/step - loss: 0.3449 - accuracy: 0.8792\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5443 - accuracy: 0.8093\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4068 - accuracy: 0.8550\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3681 - accuracy: 0.8676\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3422 - accuracy: 0.8748\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3236 - accuracy: 0.8808\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8761\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5456 - accuracy: 0.8116\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4057 - accuracy: 0.8563\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3697 - accuracy: 0.8679\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3420 - accuracy: 0.8757\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3219 - accuracy: 0.8830\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3592 - accuracy: 0.8712\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5014 - accuracy: 0.8227\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3745 - accuracy: 0.8639\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3367 - accuracy: 0.8762\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8844\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2939 - accuracy: 0.8916\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3092 - accuracy: 0.8872\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4976 - accuracy: 0.8234\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3738 - accuracy: 0.8652\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3362 - accuracy: 0.8773\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3102 - accuracy: 0.8859\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2921 - accuracy: 0.8921\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3221 - accuracy: 0.8845\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5062 - accuracy: 0.8208\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3762 - accuracy: 0.8635\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3383 - accuracy: 0.8765\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3143 - accuracy: 0.8835\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2957 - accuracy: 0.8920\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3076 - accuracy: 0.8908\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5024 - accuracy: 0.8216\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3745 - accuracy: 0.8636\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3392 - accuracy: 0.8757\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3130 - accuracy: 0.8846\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2950 - accuracy: 0.8906\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3321 - accuracy: 0.8816\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5027 - accuracy: 0.8241\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3755 - accuracy: 0.8633\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3363 - accuracy: 0.8762\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3108 - accuracy: 0.8844\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2931 - accuracy: 0.8905\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3346 - accuracy: 0.8793\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5689 - accuracy: 0.8071\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4348 - accuracy: 0.8488\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4015 - accuracy: 0.8610\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3809 - accuracy: 0.8661\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3623 - accuracy: 0.8714\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3515 - accuracy: 0.8746\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3394 - accuracy: 0.8788\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3297 - accuracy: 0.8807\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3208 - accuracy: 0.8838\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3148 - accuracy: 0.8863\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3558 - accuracy: 0.8733\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5719 - accuracy: 0.8054\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4176 - accuracy: 0.8526\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3838 - accuracy: 0.8637\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3592 - accuracy: 0.8708\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3414 - accuracy: 0.8785\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3273 - accuracy: 0.8815\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3167 - accuracy: 0.8847\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3074 - accuracy: 0.8880\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3003 - accuracy: 0.8913\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2925 - accuracy: 0.8932\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8664\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5702 - accuracy: 0.8043\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4179 - accuracy: 0.8528\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3878 - accuracy: 0.8628\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3635 - accuracy: 0.8711\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3487 - accuracy: 0.8749\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.8807\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3234 - accuracy: 0.8832\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3126 - accuracy: 0.8874\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3083 - accuracy: 0.8877\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3010 - accuracy: 0.8902\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3363 - accuracy: 0.8799\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5696 - accuracy: 0.8039\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4260 - accuracy: 0.8495\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3921 - accuracy: 0.8593\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3712 - accuracy: 0.8674\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3513 - accuracy: 0.8739\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3378 - accuracy: 0.8786\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3274 - accuracy: 0.8821\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3150 - accuracy: 0.8850\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3060 - accuracy: 0.8891\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2978 - accuracy: 0.8899\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3711 - accuracy: 0.8752\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5721 - accuracy: 0.8024\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4295 - accuracy: 0.8495\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3931 - accuracy: 0.8602\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3738 - accuracy: 0.8685\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3607 - accuracy: 0.8721\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3415 - accuracy: 0.8766\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3317 - accuracy: 0.8807\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3204 - accuracy: 0.8840\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3126 - accuracy: 0.8857\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3048 - accuracy: 0.8888\n",
            "375/375 [==============================] - 0s 998us/step - loss: 0.3600 - accuracy: 0.8742\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5436 - accuracy: 0.8114\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4132 - accuracy: 0.8536\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3702 - accuracy: 0.8674\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3430 - accuracy: 0.8784\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3278 - accuracy: 0.8801\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3114 - accuracy: 0.8858\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2974 - accuracy: 0.8914\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2883 - accuracy: 0.8934\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2795 - accuracy: 0.8973\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2707 - accuracy: 0.8999\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8786\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5439 - accuracy: 0.8122\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4086 - accuracy: 0.8555\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3657 - accuracy: 0.8707\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3433 - accuracy: 0.8761\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3238 - accuracy: 0.8819\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3057 - accuracy: 0.8894\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2919 - accuracy: 0.8937\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2839 - accuracy: 0.8960\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2764 - accuracy: 0.8978\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2674 - accuracy: 0.9020\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8767\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5454 - accuracy: 0.8098\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4057 - accuracy: 0.8551\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3658 - accuracy: 0.8683\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3419 - accuracy: 0.8751\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3210 - accuracy: 0.8824\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3054 - accuracy: 0.8883\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2937 - accuracy: 0.8925\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2814 - accuracy: 0.8958\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2714 - accuracy: 0.9005\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2643 - accuracy: 0.9019\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3347 - accuracy: 0.8801\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5337 - accuracy: 0.8159\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4016 - accuracy: 0.8572\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3632 - accuracy: 0.8683\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3393 - accuracy: 0.8762\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3209 - accuracy: 0.8823\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3087 - accuracy: 0.8866\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2959 - accuracy: 0.8913\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2844 - accuracy: 0.8957\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2743 - accuracy: 0.8991\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2677 - accuracy: 0.9015\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3271 - accuracy: 0.8867\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5400 - accuracy: 0.8134\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4085 - accuracy: 0.8564\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3659 - accuracy: 0.8682\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3414 - accuracy: 0.8767\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3214 - accuracy: 0.8828\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3079 - accuracy: 0.8860\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2948 - accuracy: 0.8910\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2828 - accuracy: 0.8956\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2733 - accuracy: 0.8998\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2642 - accuracy: 0.9031\n",
            "375/375 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8725\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5024 - accuracy: 0.8221\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3794 - accuracy: 0.8639\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - ETA: 0s - loss: 0.3392 - accuracy: 0.87 - 3s 2ms/step - loss: 0.3387 - accuracy: 0.8763\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3145 - accuracy: 0.8863\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2959 - accuracy: 0.8915\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2800 - accuracy: 0.8969\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2672 - accuracy: 0.9011\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2545 - accuracy: 0.9042\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2444 - accuracy: 0.9085\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2322 - accuracy: 0.9131\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3213 - accuracy: 0.8845\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5046 - accuracy: 0.8237\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3760 - accuracy: 0.8653\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3355 - accuracy: 0.8767\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3111 - accuracy: 0.8861\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2900 - accuracy: 0.8933\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.8963\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2633 - accuracy: 0.9027\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2517 - accuracy: 0.9072\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2418 - accuracy: 0.9106\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2322 - accuracy: 0.9141\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3247 - accuracy: 0.8828\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5048 - accuracy: 0.8211\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3784 - accuracy: 0.8625\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3339 - accuracy: 0.8770\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3103 - accuracy: 0.8874\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2904 - accuracy: 0.8931\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2777 - accuracy: 0.8970\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2641 - accuracy: 0.8995\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2503 - accuracy: 0.9053\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2398 - accuracy: 0.9113\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2338 - accuracy: 0.9120\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3019 - accuracy: 0.8932\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5012 - accuracy: 0.8221\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3762 - accuracy: 0.8625\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3370 - accuracy: 0.8751\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3110 - accuracy: 0.8852\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2923 - accuracy: 0.8909\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2769 - accuracy: 0.8968\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2636 - accuracy: 0.9007\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2535 - accuracy: 0.9036\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2420 - accuracy: 0.9078\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2322 - accuracy: 0.9121\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3247 - accuracy: 0.8882\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5028 - accuracy: 0.8226\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3763 - accuracy: 0.8633\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3355 - accuracy: 0.8773\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3097 - accuracy: 0.8857\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2926 - accuracy: 0.8918\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2731 - accuracy: 0.8997\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2632 - accuracy: 0.9022\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2508 - accuracy: 0.9051\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2386 - accuracy: 0.9105\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2296 - accuracy: 0.9146\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3057 - accuracy: 0.8936\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4865 - accuracy: 0.8278\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3624 - accuracy: 0.8688\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3282 - accuracy: 0.8804\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3038 - accuracy: 0.8869\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2860 - accuracy: 0.8946\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2702 - accuracy: 0.8992\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2556 - accuracy: 0.9040\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2459 - accuracy: 0.9079\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2365 - accuracy: 0.9115\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2261 - accuracy: 0.9148\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000022C57141430>,\n",
              "             param_grid={'epochs': [1, 5, 10], 'hidden_size': [32, 64, 256]})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def make_model(optimizer=\"adam\", hidden_size=128):\n",
        "    model = K.models.Sequential([\n",
        "        K.layers.Flatten(input_shape=(28, 28)),\n",
        "        K.layers.Dense(hidden_size, input_shape=(784, ), activation='relu'),\n",
        "        K.layers.Dense(10)\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=K.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "clf = KerasClassifier(make_model)\n",
        "param_grid = {'epochs': [1, 5, 10],\n",
        "              'hidden_size': [32, 64, 256]}\n",
        "grid = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
        "grid.fit(train_images, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-kuUrnerufU",
        "outputId": "d6b5f27a-5bf6-4419-8f10-1a74c9eacb9b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_epochs</th>\n",
              "      <th>param_hidden_size</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
              "      <th>32</th>\n",
              "      <td>0.837983</td>\n",
              "      <td>0.846250</td>\n",
              "      <td>0.837000</td>\n",
              "      <td>0.821417</td>\n",
              "      <td>0.850417</td>\n",
              "      <td>0.834833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.848783</td>\n",
              "      <td>0.847917</td>\n",
              "      <td>0.847417</td>\n",
              "      <td>0.857250</td>\n",
              "      <td>0.847417</td>\n",
              "      <td>0.843917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.849250</td>\n",
              "      <td>0.858500</td>\n",
              "      <td>0.846833</td>\n",
              "      <td>0.856250</td>\n",
              "      <td>0.854583</td>\n",
              "      <td>0.830083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
              "      <th>32</th>\n",
              "      <td>0.864400</td>\n",
              "      <td>0.860917</td>\n",
              "      <td>0.865417</td>\n",
              "      <td>0.860583</td>\n",
              "      <td>0.866917</td>\n",
              "      <td>0.868167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.874500</td>\n",
              "      <td>0.876417</td>\n",
              "      <td>0.869500</td>\n",
              "      <td>0.879250</td>\n",
              "      <td>0.876083</td>\n",
              "      <td>0.871250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.884683</td>\n",
              "      <td>0.887167</td>\n",
              "      <td>0.884500</td>\n",
              "      <td>0.890833</td>\n",
              "      <td>0.881583</td>\n",
              "      <td>0.879333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
              "      <th>32</th>\n",
              "      <td>0.873833</td>\n",
              "      <td>0.873333</td>\n",
              "      <td>0.866417</td>\n",
              "      <td>0.879917</td>\n",
              "      <td>0.875250</td>\n",
              "      <td>0.874250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.878917</td>\n",
              "      <td>0.878583</td>\n",
              "      <td>0.876750</td>\n",
              "      <td>0.880083</td>\n",
              "      <td>0.886667</td>\n",
              "      <td>0.872500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.888467</td>\n",
              "      <td>0.884500</td>\n",
              "      <td>0.882833</td>\n",
              "      <td>0.893250</td>\n",
              "      <td>0.888167</td>\n",
              "      <td>0.893583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                mean_test_score  split0_test_score  \\\n",
              "param_epochs param_hidden_size                                       \n",
              "1            32                        0.837983           0.846250   \n",
              "             64                        0.848783           0.847917   \n",
              "             256                       0.849250           0.858500   \n",
              "5            32                        0.864400           0.860917   \n",
              "             64                        0.874500           0.876417   \n",
              "             256                       0.884683           0.887167   \n",
              "10           32                        0.873833           0.873333   \n",
              "             64                        0.878917           0.878583   \n",
              "             256                       0.888467           0.884500   \n",
              "\n",
              "                                split1_test_score  split2_test_score  \\\n",
              "param_epochs param_hidden_size                                         \n",
              "1            32                          0.837000           0.821417   \n",
              "             64                          0.847417           0.857250   \n",
              "             256                         0.846833           0.856250   \n",
              "5            32                          0.865417           0.860583   \n",
              "             64                          0.869500           0.879250   \n",
              "             256                         0.884500           0.890833   \n",
              "10           32                          0.866417           0.879917   \n",
              "             64                          0.876750           0.880083   \n",
              "             256                         0.882833           0.893250   \n",
              "\n",
              "                                split3_test_score  split4_test_score  \n",
              "param_epochs param_hidden_size                                        \n",
              "1            32                          0.850417           0.834833  \n",
              "             64                          0.847417           0.843917  \n",
              "             256                         0.854583           0.830083  \n",
              "5            32                          0.866917           0.868167  \n",
              "             64                          0.876083           0.871250  \n",
              "             256                         0.881583           0.879333  \n",
              "10           32                          0.875250           0.874250  \n",
              "             64                          0.886667           0.872500  \n",
              "             256                         0.888167           0.893583  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = pd.DataFrame(grid.cv_results_)\n",
        "res.pivot_table(index=['param_epochs', 'param_hidden_size'],\n",
        "                values=[ 'split0_test_score','split1_test_score','split2_test_score','split3_test_score','split4_test_score','mean_test_score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG20j-njsmH2"
      },
      "source": [
        "## II. Convolutional Neural Networks\n",
        "\n",
        "### Ideas\n",
        "- Dense layers may contain redudent connections\n",
        "- Some information should be invariant to spacial translation\n",
        "- The number of parameters can be reduced if certain weights share the same value.\n",
        "\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcS4LZdFg5QPbgDb-jvP-YT0N51eRkWg45uF0ybsB5k0Ubr0-gOC&usqp=CAU\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swsVEzVaIGS1"
      },
      "source": [
        "### Definition of Convolution\n",
        "\n",
        "**Continous convolution**: The convolution of two real-valued function $f, g$ is a function defined as\n",
        "$$(f*g)(x) := \\int_{-\\infty}^\\infty f(t)g(x-t)dt$$\n",
        "\n",
        "<img src=\"https://i.stack.imgur.com/oJ5Za.png\" width=\"300\"><img src=\"https://fiveko.com/assets/pics/math/gauss1d_shape.jpg\" width=\"300\">\n",
        "\n",
        "**Discrete convolution**: The convolution of two sequence $\\{f[n]\\}_{n=-\\infty}^\\infty$ and $\\{g[n]\\}_{n=-\\infty}^\\infty$ is a sequence defined as\n",
        "$$(f*g)[n] := \\sum_{t=-\\infty}^\\infty f[t]g[n-t]$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9W2eW2JNlKg"
      },
      "source": [
        "### 2D Convolution Layer\n",
        "<img src=\"https://cdn-media-1.freecodecamp.org/images/Gjxh-aApWTzIRI1UNmGnNLrk8OKsQaf2tlDu\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0CrFLT3Oo8y"
      },
      "source": [
        "**2D smoothing with Gaussian kernel**\n",
        "\n",
        "<img src=\"https://www.cs.umd.edu/class/fall2016/cmsc426/matlab/filters/html/filters_tutorial_03.png\" width=\"400\"><img src=\"https://www.mathworks.com/help/examples/stats/win64/ComputeTheMultivariateNormalPdfExample_01.png\" width=\"200\">\n",
        "\n",
        "**Edge detection**\n",
        "\n",
        "<img src=\"https://x-wei.github.io/images/Ng_DLMooc_c4wk1/pasted_image004.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW9tmrRSK-T3"
      },
      "source": [
        "### LeNet5 on MNIST\n",
        "\n",
        "Yann LeCun, Leon Bottou, Yosuha Bengio and Patrick Haffner proposed a neural network architecture for handwritten and machine-printed character recognition in 1990’s which they called LeNet-5. It is one of the early example of a convolutional neural network\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png\" width=\"600\">\n",
        "\n",
        "Reference:\n",
        "\n",
        "LeCun, Yann, et al. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE 86.11 (1998): 2278-2324."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxIG1f5zOgT1"
      },
      "source": [
        "### Max-Pooling Layer\n",
        "<img src=\"https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn5zEZiuQevA",
        "outputId": "8be31424-ce07-40b2-ec34-d96fbb2eeb45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Load and prepare the MNIST dataset.\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Convert the data from integers to floating-point numbers\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "print(x_train.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beP425_zO9rQ"
      },
      "outputs": [],
      "source": [
        "model_cnn = tf.keras.Sequential()\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Conv2D(filters=6,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 activation='relu',\n",
        "                                 input_shape=(28, 28, 1)))\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Conv2D(filters=16,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 activation='relu'))\n",
        "\n",
        "model_cnn.add(tf.keras.layers.AveragePooling2D())\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model_cnn.add(tf.keras.layers.Dense(units=120,\n",
        "                       activation='relu'))\n",
        "model_cnn.add(tf.keras.layers.Dense(units=84,\n",
        "                       activation='relu'))\n",
        "model_cnn.add(tf.keras.layers.Dense(units=10,\n",
        "                       activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9exx1n6QUsu",
        "outputId": "763cd9f8-6bb1-4205-8a0d-ebac02a85108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 6)         60        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 16)        880       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_48 (Flatten)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 120)               276600    \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 288,554\n",
            "Trainable params: 288,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3oVJJY9QYJ4"
      },
      "outputs": [],
      "source": [
        "model_cnn.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMPYf168QZmu",
        "outputId": "b65599ee-8c40-4046-853b-8c6bad577c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\burd8\\Anaconda3\\envs\\py38\\lib\\site-packages\\keras\\backend.py:4906: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1562 - accuracy: 0.9531\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0492 - accuracy: 0.9847\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0329 - accuracy: 0.9895\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0225 - accuracy: 0.9930\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0162 - accuracy: 0.9949\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0138 - accuracy: 0.9956\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0108 - accuracy: 0.9963\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0081 - accuracy: 0.9974\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0075 - accuracy: 0.9977\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0073 - accuracy: 0.9976\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x22c58b8f4f0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_cnn.fit(x_train.reshape(list(x_train.shape) + [1]), y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUAKjUG0QanL",
        "outputId": "05749ce2-71af-482e-a4b2-2f1fd2ab4607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9888\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.05030299350619316, 0.9887999892234802]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_cnn.evaluate(x_test.reshape(list(x_test.shape) + [1]), y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5tLVxvwQqrk"
      },
      "source": [
        "### Discussion: How to evaluate this model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-Ia3P_oQ2zx"
      },
      "source": [
        "## III. Extra: Recurrent Neural Network\n",
        "\n",
        "### Idea\n",
        "- In some applications, data arrive in a sequence.\n",
        "- The model should remember the history.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/text/tutorials/images/text_generation_training.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC2frl56TpGR"
      },
      "source": [
        "## Text Generation with a Recurrent Neurual Network\n",
        "- We will work with a dataset of Shakespeare's writing\n",
        "- Build a model with `tf.keras` to analyze the sequence of characters\n",
        "- Apply the model to write new text in Shakespeare's style\n",
        "\n",
        "This project is adapted from [TensorFlow tutorial](https://www.tensorflow.org/tutorials/sequences/text_generation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "Dunw2eNXTA7w",
        "outputId": "f5ae2067-dd01-4320-ad2e-de128ed054c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Get the text file from:\n",
        "# https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jMh6jlvKTYst",
        "outputId": "41cca445-b4ea-405f-81ab-66eec3ae5441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read the text as a string\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "GVBOeZX7Tafa",
        "outputId": "f1fd9608-3e72-4807-b6f6-217970e9e1c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xYM0dQAGTcVb",
        "outputId": "c357a733-a137-4be0-b079-0f19710d612e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "# Python set is a data structure containing unique elements\n",
        "vocab = sorted(set(text))\n",
        "# Print with formatted string: {index:format}\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erTeWyiMTj2d"
      },
      "source": [
        "### Vectorize the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzRYCiO3Tf07"
      },
      "outputs": [],
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "# enumerate: returns index and the value\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "DI0ieDf5TjI2",
        "outputId": "b758bb9a-54f5-4d71-b21c-03326633bc74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '$' :   3,\n",
            "  '&' :   4,\n",
            "  \"'\" :   5,\n",
            "  ',' :   6,\n",
            "  '-' :   7,\n",
            "  '.' :   8,\n",
            "  '3' :   9,\n",
            "  ':' :  10,\n",
            "  ';' :  11,\n",
            "  '?' :  12,\n",
            "  'A' :  13,\n",
            "  'B' :  14,\n",
            "  'C' :  15,\n",
            "  'D' :  16,\n",
            "  'E' :  17,\n",
            "  'F' :  18,\n",
            "  'G' :  19,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "K2JIJ0JIT877",
        "outputId": "ab39a4a9-29cf-42e7-dd82-202209c0ee46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ],
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "# repr: string representation of an object\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "B6t5h_B-T_og",
        "outputId": "ba236b06-35ba-452d-ab33-ad64a9071ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n"
          ]
        }
      ],
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//seq_length\n",
        "\n",
        "# Create training examples / targets\n",
        "# Dataset.from_tensor_slices(): convert a numpy array to tf Dataset\n",
        "# Dataset.take(): create a sub Dataset\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "ObpgiEH9UCzb",
        "outputId": "d0d62567-b6bc-4f25-99a5-fa22a6dd1ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "# batch(): cut the dataset into chunks\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "# join(): concatenate a list of elements and form a string\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNHC5o4HUGT1"
      },
      "outputs": [],
      "source": [
        "# For each sequence, duplicate and shift it to form the input and target text by using the `map` method\n",
        "# to apply a simple function to each batch\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "kcd9990nXQF-",
        "outputId": "9434d069-a134-4d9e-8926-32023d6fc12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "# Print the first example input and target values:\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJVKNgnoXVzB"
      },
      "source": [
        "Each index of these vectors are processed as one time step. For the input at time step 0, the model receives the index for \"F\" and trys to predict the index for \"i\" as the next character. At the next timestep, it does the same thing but the RNN considers the previous step context in addition to the current input character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "LJ77ZalDXbSL",
        "outputId": "1c058ce7-df92-4254-e3e9-d364e70b10d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 18 ('F')\n",
            "  expected output: 47 ('i')\n",
            "Step    1\n",
            "  input: 47 ('i')\n",
            "  expected output: 56 ('r')\n",
            "Step    2\n",
            "  input: 56 ('r')\n",
            "  expected output: 57 ('s')\n",
            "Step    3\n",
            "  input: 57 ('s')\n",
            "  expected output: 58 ('t')\n",
            "Step    4\n",
            "  input: 58 ('t')\n",
            "  expected output: 1 (' ')\n"
          ]
        }
      ],
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "yuVCf_dKXdF1",
        "outputId": "1adf8f52-5d8f-4bf1-9f33-7a7b9f11a787"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create training batches\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LUiLr37Xqgw"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MJ_GWdfXofU"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlvF8OVcXsen"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CT-aV_PXuPX"
      },
      "outputs": [],
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sw4VEN2UXvib",
        "outputId": "5e34040f-9918-4887-954d-4ed1487c4752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "unAraUZGX0s2",
        "outputId": "39fbda54-4ae5-4b1a-e299-94835c0c31c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvXEpfZ6X2Xw"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "EmPx9xccX6o5",
        "outputId": "420aaef0-ea48-4c27-a9d8-85622fd9ff06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: \n",
            " \"used:\\nMy brother Gloucester, plain well-meaning soul,\\nWhom fair befal in heaven 'mongst happy souls!\"\n",
            "\n",
            "Next Char Predictions: \n",
            " 'OWkUBZEUUS$oU s?FaHPIdMip&\\nn3 nLeWhdvqWnv-L;jMGZLDBeMt$zQ.cCjL!eRezcwLzVhEqBMutWaNDMsiLvioUU-oYz:Ku3'\n"
          ]
        }
      ],
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "uJviHNwBX8N0",
        "outputId": "468bb558-cf4f-495f-c696-6337ff83beb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.17439\n"
          ]
        }
      ],
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXhAsD_jX-EZ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa-PGmWaX_vP"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "WcPfedNlYBIA",
        "outputId": "dd2520a2-c078-43f5-a9f6-a5b6b6dd0f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 2.6875\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 1.9653\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 1.7006\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 1.5502\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 1.4600\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 1.4000\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.3527\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.3145\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.2790\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.2457\n"
          ]
        }
      ],
      "source": [
        "EPOCHS=10\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjKpfep6dswa"
      },
      "outputs": [],
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Le2Qahdo2B"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "u-zzqIOrdw9I",
        "outputId": "843f0e70-a8e5-46f3-f954-719f311586a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO: shall hence at her\n",
            "Buside friends of place withal.\n",
            "Welcomely as I day goods; 'They upon your chamber. Come,\n",
            "Thou given tyrann: thy sovereign's language,\n",
            "Not like the head, you arrived in thine,\n",
            "Now still of England's dishope more than you.\n",
            "\n",
            "PETRUCHIO:\n",
            "So, sir, it says, sweet bark all lible.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "Uthen thou art solries; he fightest mine:\n",
            "Stepiou stook with her for ill-upon us.\n",
            "\n",
            "BRUTUS:\n",
            "The days, my father, too,\n",
            "When he forced to the Gody be as springed\n",
            "Thy widonoow: thing watch'd hishorn.\n",
            "Thus even so I think, are you.\n",
            "\n",
            "LUCIO:\n",
            "I have crafted you with dishonour dead,\n",
            "But he hath in cir him than in think it presemenish'd\n",
            "Young Richard that weter-full thine,\n",
            "your mother with oriel house extee swift in her,\n",
            "Shit much on, here comes it to die:\n",
            "Y then will your good he from the lowe I should\n",
            "What I have made, than if the stepher,\n",
            "Carting, for our friends, Richmond.\n",
            "\n",
            "LEONTES:\n",
            "So all use is all his negless.\n",
            "\n",
            "POLIXENES:\n",
            "Your grace seizs so you then must I am. To help thee to far o\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, u\"ROMEO: \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JB-M9t4AVOZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-LUiLr37Xqgw"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "py38",
      "language": "python",
      "name": "py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}