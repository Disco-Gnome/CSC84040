{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8B30JW8BJb"
      },
      "source": [
        "# BM25 Algorithm Explanation and Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NN0C9rp8BJc"
      },
      "source": [
        "### 1. Introduction to BM25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIVRL25u8BJc"
      },
      "source": [
        "BM25 (Best Matching 25) is a ranking function used in information retrieval to estimate the relevance of documents to a given search query. It's an improvement over the basic TF-IDF weighting scheme.\n",
        "\n",
        "The main idea behind BM25 is to rank documents based on the query terms appearing in each document, considering:\n",
        "1. Term frequency (TF)\n",
        "2. Inverse document frequency (IDF)\n",
        "3. Document length normalization\n",
        "\n",
        "The BM25 formula is:\n",
        "\n",
        "$$\n",
        "\\text{score}(D, Q) = \\sum \\left( \\text{IDF}(q_i) \\cdot \\frac{f(q_i, D) \\cdot (k1 + 1)}{f(q_i, D) + k1 \\cdot (1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}})} \\right)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- D is a document\n",
        "- Q is a query containing terms q_i\n",
        "- f(q_i, D) is the frequency of q_i in D\n",
        "- |D| is the length of document D\n",
        "- avgdl is the average document length in the corpus\n",
        "- k1 and b are free parameters (usually k1 âˆˆ [1.2, 2.0] and b = 0.75)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yJ_-ODG8BJd"
      },
      "source": [
        "### 2. Implementing BM25"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "W-3EA8DX8zk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSGbKVOe8BJe"
      },
      "outputs": [],
      "source": [
        "class BM25:\n",
        "    def __init__(self, corpus: list[list[str]], k1: float = 1.2, b: float = 0.75):\n",
        "        self.corpus = corpus\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.avgdl = sum(len(doc) for doc in corpus) / len(corpus)\n",
        "        self.doc_freqs = self._calculate_doc_freqs()\n",
        "        self.idf = self._calculate_idf()\n",
        "        self.doc_lengths = [len(doc) for doc in corpus]\n",
        "\n",
        "    def _calculate_doc_freqs(self) -> dict[str, int]:\n",
        "        doc_freqs = {}\n",
        "        for doc in self.corpus:\n",
        "            for term in set(doc):\n",
        "                doc_freqs[term] = doc_freqs.get(term, 0) + 1\n",
        "        return doc_freqs\n",
        "\n",
        "    def _calculate_idf(self) -> dict[str, float]:\n",
        "        idf = {}\n",
        "        num_docs = len(self.corpus)\n",
        "        for term, freq in self.doc_freqs.items():\n",
        "            idf[term] = math.log((num_docs - freq + 0.5) / (freq + 0.5) + 1)\n",
        "        return idf\n",
        "\n",
        "    def _score_document(self, query: list[str], doc_index: int) -> float:\n",
        "        score = 0\n",
        "        doc = self.corpus[doc_index]\n",
        "        doc_len = self.doc_lengths[doc_index]\n",
        "\n",
        "        for term in query:\n",
        "            if term not in doc:\n",
        "                continue\n",
        "            tf = doc.count(term)\n",
        "            numerator = self.idf[term] * tf * (self.k1 + 1)\n",
        "            denominator = tf + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)\n",
        "            score += numerator / denominator\n",
        "\n",
        "        return score\n",
        "\n",
        "    def rank_documents(self, query: list[str]) -> list[int]:\n",
        "        scores = [self._score_document(query, i) for i in range(len(self.corpus))]\n",
        "        return sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7grKVY_8BJf"
      },
      "source": [
        "### 3. Example Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi4O3Y8r8BJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0f5b68-37a1-40d4-e3e3-e690a82f7d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked document indices: [2, 0, 1, 3]\n"
          ]
        }
      ],
      "source": [
        "# Sample corpus\n",
        "corpus = [\n",
        "    [\"hello\", \"world\", \"hello\", \"there\"],\n",
        "    [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"],\n",
        "    [\"information\", \"retrieval\", \"is\", \"the\", \"science\", \"of\", \"searching\", \"for\", \"information\"],\n",
        "    [\"machine\", \"learning\", \"is\", \"a\", \"subset\", \"of\", \"artificial\", \"intelligence\"],\n",
        "]\n",
        "\n",
        "# Initialize BM25\n",
        "bm25 = BM25(corpus)\n",
        "\n",
        "# Example query\n",
        "query = [\"information\", \"retrieval\"]\n",
        "\n",
        "# Rank documents\n",
        "ranked_docs = bm25.rank_documents(query)\n",
        "\n",
        "print(\"Ranked document indices:\", ranked_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdk-U6VX8BJf"
      },
      "source": [
        "### 4. Explanation of the Implementation\n",
        "\n",
        "Let's break down the implementation:\n",
        "\n",
        "1. The BM25 class is initialized with a corpus, and optional parameters k1 and b.\n",
        "2. In the constructor, we calculate:\n",
        "   - Average document length (avgdl)\n",
        "   - Document frequencies (how many documents contain each term)\n",
        "   - Inverse Document Frequency (IDF) for each term\n",
        "   - Document lengths\n",
        "3. The _score_document method calculates the BM25 score for a single document given a query.\n",
        "4. The rank_documents method scores all documents for a given query and returns their indices sorted by relevance.\n",
        "\n",
        "This implementation demonstrates the key components of BM25:\n",
        "- Term frequency (tf) is calculated directly in _score_document\n",
        "- IDF is pre-calculated in _calculate_idf\n",
        "- Document length normalization is applied in _score_document\n",
        "\n",
        "Students can experiment with different values of k1 and b to see how they affect the rankings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYwek_-8BJf"
      },
      "source": [
        "### 5. (Optional) Exercises for Students\n",
        "\n",
        "1. Implement a function to calculate precision@k for the BM25 rankings.\n",
        "2. Modify the BM25 class to handle stop words removal and stemming.\n",
        "3. Compare BM25 rankings with simple TF-IDF rankings. What differences do you observe?\n",
        "4. Implement a variation of BM25, such as BM25+ or BM25L, and compare the results.\n",
        "5. Use a real-world dataset (e.g., news articles) to test the BM25 implementation and analyze the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOG8cPnb8BJg"
      },
      "source": [
        "#### BM25+ Equation\n",
        "\n",
        "$$\n",
        "\\text{score}(D, Q) = \\sum_{i=1}^n \\text{IDF}(q_i) \\cdot \\left(\\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}})} + \\delta\\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRPl0DsR8BJg"
      },
      "source": [
        "#### BM25L Equation\n",
        "\n",
        "The BM25L scoring function for a term $t$ in a document $d$ is:\n",
        "\n",
        "$$\n",
        "\\text{score}(d,t) = \\text{IDF}(t) \\cdot \\frac{f'(t,d) \\cdot (k_1 + 1)}{f'(t,d) + k_1}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$$\n",
        "f'(t,d) = \\frac{\\text{tf}'(t,d)}{1 - b + b \\cdot \\text{dl}'(d)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{dl}'(d) = \\frac{\\text{dl}(d)}{\\text{avdl}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{tf}'(t,d) = \\text{tf}(t,d) \\cdot \\log_2\\left(1 + c \\cdot \\frac{\\text{avdl}}{\\text{dl}(d)}\\right)\n",
        "$$\n",
        "\n",
        "And:\n",
        "\n",
        "- $\\text{IDF}(t)$ is the inverse document frequency of term $t$\n",
        "- $\\text{tf}(t,d)$ is the term frequency of $t$ in document $d$\n",
        "- $\\text{dl}(d)$ is the length of document $d$\n",
        "- $\\text{avdl}$ is the average document length in the collection\n",
        "- $k_1$ and $b$ are the usual BM25 parameters\n",
        "- $c$ is a new parameter (typically set to 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOdFVr8q8BJh"
      },
      "source": [
        "# Comparison of BM25, BM25L, and BM25+\n",
        "\n",
        "## Formulas\n",
        "\n",
        "### BM25\n",
        "$$\n",
        "\\text{score}(D, Q) = \\sum_{i=1}^n \\text{IDF}(q_i) \\cdot \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}})}\n",
        "$$\n",
        "\n",
        "### BM25L\n",
        "$$\n",
        "\\text{score}(D, Q) = \\sum_{i=1}^n \\text{IDF}(q_i) \\cdot \\frac{f'(q_i, D) \\cdot (k_1 + 1)}{f'(q_i, D) + k_1}\n",
        "$$\n",
        "Where:\n",
        "$$\n",
        "f'(q_i, D) = \\frac{\\text{tf}'(q_i, D)}{1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}}}\n",
        "$$\n",
        "$$\n",
        "\\text{tf}'(q_i, D) = \\text{tf}(q_i, D) \\cdot \\log_2\\left(1 + c \\cdot \\frac{\\text{avgdl}}{|D|}\\right)\n",
        "$$\n",
        "\n",
        "### BM25+\n",
        "$$\n",
        "\\text{score}(D, Q) = \\sum_{i=1}^n \\text{IDF}(q_i) \\cdot \\left(\\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}})} + \\delta\\right)\n",
        "$$\n",
        "\n",
        "## Key Differences\n",
        "\n",
        "1. **Document Length Normalization**\n",
        "   - BM25: Uses $\\frac{|D|}{\\text{avgdl}}$ in the denominator.\n",
        "   - BM25L: Incorporates document length in both $f'(q_i, D)$ and $\\text{tf}'(q_i, D)$.\n",
        "   - BM25+: Same as BM25, but adds $\\delta$ term.\n",
        "\n",
        "2. **Term Frequency Handling**\n",
        "   - BM25: Uses raw term frequency $f(q_i, D)$.\n",
        "   - BM25L: Uses modified term frequency $\\text{tf}'(q_i, D)$ with logarithmic scaling.\n",
        "   - BM25+: Uses raw term frequency $f(q_i, D)$, like BM25.\n",
        "\n",
        "3. **Additional Parameters**\n",
        "   - BM25: Uses $k_1$ and $b$.\n",
        "   - BM25L: Introduces new parameter $c$ (typically set to 1).\n",
        "   - BM25+: Introduces new parameter $\\delta$ (small constant, often around 1).\n",
        "\n",
        "## Strengths and Weaknesses\n",
        "\n",
        "### BM25\n",
        "- **Strengths**: Well-established, widely used, good general performance.\n",
        "- **Weaknesses**: Can undervalue long documents, especially for terms not present.\n",
        "\n",
        "### BM25L\n",
        "- **Strengths**: Better handling of very long documents, addresses some BM25 limitations.\n",
        "- **Weaknesses**: More complex, additional parameter to tune.\n",
        "\n",
        "### BM25+\n",
        "- **Strengths**: Mitigates long document undervaluation, simple modification to BM25.\n",
        "- **Weaknesses**: May overcompensate for some queries, $\\delta$ needs tuning.\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "- **BM25**: General purpose, good starting point for most applications.\n",
        "- **BM25L**: Collections with wide range of document lengths, especially with very long documents.\n",
        "- **BM25+**: When long documents are important but BM25L's complexity is undesirable.\n",
        "\n",
        "## Implementation Considerations\n",
        "\n",
        "1. **Complexity**: BM25 < BM25+ < BM25L\n",
        "2. **Parameter Tuning**:\n",
        "   - BM25: $k_1$ and $b$\n",
        "   - BM25L: $k_1$, $b$, and $c$\n",
        "   - BM25+: $k_1$, $b$, and $\\delta$\n",
        "3. **Computational Cost**: BM25L may be slightly more expensive due to additional logarithm calculation.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Each variant has its strengths and is suited to different scenarios. The choice between them depends on the specific characteristics of the document collection and the retrieval tasks at hand. Experimentation and evaluation on the target dataset are recommended to determine the best approach for a given application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prb-hq0V8BJh"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}